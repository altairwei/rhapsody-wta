import matplotlib
matplotlib.use('agg')
import matplotlib.pyplot as plt
from mist.apps import split
from mist.apps import merge
from mist.apps import preprocessing
import numpy as np
import scipy.sparse
import os
import os.path
import glob
import argparse
import csv
import sys
import time
import shutil
import gzip
from mist.apps import utils
from mist.apps._version import __version__


def main():
    des = 'Cluster Analysis, part of Rhapsody Analysis version ' + __version__
    parser = argparse.ArgumentParser(description=des, add_help=True)

    parser.add_argument('--datatable', action='store', dest='data_table', required=True,
                        help='Name(s) of the MolsPerCell or Expression Matrix file. Should be comma separated if '
                             'multiple samples are specified. Only specify one type of datatable.')
    args = parser.parse_args()
    data_table = args.data_table
    table_list = data_table.split(',')
    output_header, run_info = utils.grab_main_header(table_list[0])
    assay = run_info[0]
    label_version = run_info[1]

    if label_version in (3, 4):
        print("No clusterAnalysis for Precise.")
        return 0

    with gzip.open(table_list[0], "rt") as f:
        for i in range(len(output_header) + 1):
            data = f.readline()
        if data.startswith('No putative cells found.') or data.startswith('Cell calling using an empty protein data'):
            print(data.strip('\n') + 'Cannot run Clustering Analysis.')
            return 0

    start = time.strftime("%Y-%m-%d %H:%M:%S")
    print("Start processing sequencing files: {}".format(start))

    # create internal and external dirs
    dir = 'ClusteringAnalysisInternal'
    cust_dir = 'ClusteringAnalysis'
    for d in [dir, cust_dir]:
        if not os.path.exists(d):
            os.makedirs(d)

    # check not mixed
    extension = []
    for table in table_list:
        extension.append(table.lower().split('.')[-2])
        if len(set(extension)) > 1:
            sys.exit('Multiple data table types specified. Make sure input consists of only MolPerCell.csv or only '
                     'Expression_Data.st files.')

    # combine tables
    if len(table_list) != 1:
        X, genes, sample = combine_samples(table_list, extension[0].lower(), dir)
        run_clust_analysis(X, genes, output_header, dir, cust_dir, sample, assay)

    else:
        sample = run_info[2]
        if extension[0].lower() == 'csv':
            X, genes = load_datatable(table_list[0], len(output_header))
        elif extension[0].lower() == 'st':
            X, genes = load_st(table_list[0], len(output_header))
        else:
            raise NameError('Unrecognized file extension: {}. Aborting analysis...'.format(extension[0]))
        run_clust_analysis(X, genes, output_header, dir, cust_dir, sample, assay)

    if assay == 'WTA':  # output filtered if WTA
        dir = 'ClusteringAnalysisInternal-fs'

    for _dir in [dir, cust_dir]:
        shutil.make_archive("{}.zip".format(os.path.basename(_dir)), "zip", _dir)
    print("Finished Clustering Analysis: {}".format(time.strftime("%Y-%m-%d %H:%M:%S")))
    return 0


def run_clust_analysis(X, genes, output_header, dir, cust_dir, sample, assay):

    # apply gene filter for both types of input, either DT or Expression matrix, so that
    # results generated by cluster analysis are the same regardless of input used
    X, genes = split.filter_genes(X, genes)

    tsne_file = os.path.join(dir, sample + '_bh-tSNEcoordinates.csv')
    # program errors out if nrow(X) - 1 < 3 * perplexity, add checkpoint so that it exits successfully
    perplexity = 15.0
    if X.shape[0] - 1 < perplexity * 3:
        print("Too few data points (cells). Perplexity is too large for the number of data points!")
        error = os.path.join(dir, '{}_error.log'.format(sample))
        with open(error, 'w') as f:
            f.write("Too few data points (cells). Perplexity is too large for the number of data points!\n Cannot run "
                    "Clustering Analysis")
        utils.execute_shell_commands(['cp {} {}'.format(error, cust_dir)])
        return

    x1, x2 = preprocessing.low_dimensional_embedding2(np.log(X + 1), pcs=50, per=perplexity)
    coord_header = '\n'.join([item for sublist in output_header for item in sublist]) + '\n' + 'Coordinate_1,Coordinate_2'
    np.savetxt(tsne_file, np.c_[x1, x2], delimiter=',', fmt='%.5f', header=coord_header, comments='')

    run_dendrosplit(X, genes, x1, x2, dir, sample, output_header)

    if assay == 'WTA':
        kept_idx = preprocessing.dropseq_gene_selection(X, z_cutoff=1, bins=20)
        de_genes = get_de_genes(dir, len(output_header))
        X = preprocessing.normalizecounts_multiplymedian(X)
        selected_genes = list(set(list(genes[kept_idx]) + de_genes))
        X, genes = split.filter_genes(X, genes, 0, selected_genes)

        # remove cells expressing 0 molecules for selected genes
        zero_cells = np.where(X.sum(axis=1).astype('bool') == False)[0]

        if len(zero_cells) > 0:
            with open(os.path.join(dir, sample + '_removed_cell_index.csv'), 'w') as fw:
                r = csv.writer(fw)
                for row in output_header:
                    r.writerow(row)
                r.writerow(str([x+1 for x in list(zero_cells)]))
            X = X[np.where(X.sum(axis=1).astype('bool'))]

        dir = 'ClusteringAnalysisInternal-fs'
        if not os.path.exists(dir):
            os.makedirs(dir)

        tsne_file = os.path.join(dir, sample + '_bh-tSNEcoordinates.csv')
        x1, x2 = preprocessing.low_dimensional_embedding2(np.log(X + 1), pcs=50, per=15.0)
        np.savetxt(tsne_file, np.c_[x1, x2], delimiter=',', fmt='%.5f', header=coord_header, comments='')
        run_dendrosplit(X, genes, x1, x2, dir, sample, output_header)

        with open(os.path.join(dir, '{}_selected_genes.csv'.format(sample)), 'w') as f:
            r = csv.writer(f)
            for row in output_header:
                r.writerow(row)
            for gene in selected_genes:
                r.writerow(gene)

    # grab output files for customers
    csvs = ' '.join(glob.glob('{}/*Clusters/*.csv'.format(dir)))
    coordinates = ' '.join(glob.glob('{}/*coordinates.csv'.format(dir)))
    plots = ' '.join(glob.glob('{}/*Clusters/*_tSNE.png'.format(dir)))
    de_genes = ' '.join(glob.glob('{}/*_selected_genes.csv'.format(dir)))
    cust_files = ' '.join([csvs, coordinates, plots, de_genes])
    utils.execute_shell_commands(['cp {} {}'.format(cust_files, cust_dir)])

    return cust_files


def load_datatable(flname, len_header):
    data = np.genfromtxt(flname, dtype=float, delimiter=',', names=True, deletechars='', skip_header=len_header)
    if data.dtype.names[0] == 'Cell_Index':
        s = 1
    else:
        s = 4
    X = data.view(np.float64).reshape(data.shape + (-1,))[:,s:]
    genes = np.array(data.dtype.names[s:])
    print(np.shape(X), np.shape(genes))
    return X, genes


def load_st(flname, len_header):
    if flname.endswith('.gz'):
        flname = utils.uncompress_file(flname)
    data = np.genfromtxt(flname, dtype=str, delimiter='\t', skip_header=len_header+1, deletechars='')
    cl, cl_ind, ind_i = np.unique(data[:, 0], return_index=True, return_inverse=True)
    cl_order = np.argsort(cl_ind)
    cl = cl[cl_order]
    ind_i = np.array([np.where(cl_order == i)[0][0] for i in ind_i])
    genes, ind_j = np.unique(data[:, 1], return_inverse=True)
    col_to_use = 6  # use dbec_adjusted_molecule
    sp_matrix = scipy.sparse.coo_matrix((data[:, col_to_use].astype(np.float64), (ind_i, ind_j)),
                                        shape=(len(cl), len(genes)))
    return sp_matrix.toarray(), genes


def load_coordinates(flname, len_header):
    X_coor = np.genfromtxt(flname, delimiter=',', skip_header=len_header + 1)
    x1, x2 = X_coor[:, 0], X_coor[:, 1]
    return x1,x2


def count_nonsingleton_clusters(y):
    return sum([1 for i in np.unique(y) if np.sum(y == i) != 1])


def save_label_to_csv(flname, label, output_header):
    header = '\n'.join([item for sublist in output_header for item in sublist]) + '\n' + 'Cluster_Label'
    np.savetxt(flname+'_Labels.csv', label.astype(int), fmt='%d', header=header, comments='')
    return


def map_label_to_nonzero(y):
    return np.array([l+1 if l != -1 else l for l in y])


def run_dendrosplit(X, genes, x1, x2, dir, sample, output_header):

    D = split.log_correlation(X)
    ys, shistory = split.dendrosplit((D, X), preprocessing='precomputed', score_threshold=5, verbose=False,
                                     disband_percentile=50)
    ys_sweep = []

    thresholds = list(range(10, 120, 5))
    for threshold in thresholds:
        ys_sweep.append(split.get_clusters_from_history(D, shistory, threshold, 50))

    a = plt.figure()
    plt.plot(thresholds, [count_nonsingleton_clusters(i) for i in ys_sweep])
    plt.grid()
    plt.xlabel('Thresholds (-log10(p-value))')
    plt.ylabel('Number of non-singleton clusters')
    plt.savefig(os.path.join(dir, sample + '_numCluster_pvalueThreshold.png'), format='png', dpi=300)
    plt.close(a)

    lowest_cutoff = None
    one_cluster_only = True
    num_cluster = [count_nonsingleton_clusters(i) for i in ys_sweep]
    for i in range(0, len(thresholds)-1):
        if (i == 0 or num_cluster[i] < num_cluster[i-1]) and num_cluster[i] == num_cluster[i+1]:
            if lowest_cutoff is None:
                lowest_cutoff = thresholds[i]

            if num_cluster[i] == 1 and not one_cluster_only:
                break

            ym, mhistory = merge.dendromerge((D, X), ys_sweep[i], score_threshold=thresholds[i]/2,
                                             preprocessing='precomputed', verbose=True, outlier_threshold_percentile=50)
            ym = split.map_singleton_to_label(ym)
            num_cluster_m = len(np.unique(ym))
            if -1 in ym:
                num_cluster_m -= 1
            if num_cluster_m <= 1 and not one_cluster_only:
                break

            directory = os.path.join(dir, str(num_cluster_m) + '-Clusters')
            sample_with_clust = sample + '_' + str(num_cluster_m) + '-Clusters'

            if not os.path.exists(directory):
                os.makedirs(directory)

            one_cluster_only = False
            ys = map_label_to_nonzero(split.map_singleton_to_label(split.str_labels_to_ints(ys_sweep[i])))
            plt.figure()
            split.plot_labels_legend(x1, x2, map_label_to_nonzero(ym),
                                     title=sample + ' -- t-SNE dimension reduction with ' + str(num_cluster_m) +' clusters',
                                     save_name=os.path.join(directory, sample_with_clust + '_tSNE'))
            save_label_to_csv(os.path.join(directory, sample_with_clust), map_label_to_nonzero(ym), output_header)
            plt.close('all')

            if num_cluster_m > 1:
                plt.figure()
                split.plot_labels_legend(x1, x2, ys,
                                         title='Splitting result using a threshold of %.0f'%(thresholds[i]),
                                         save_name=os.path.join(directory, sample +'_split_tsne'))

                split.plot_dendro(D, labels=ym, save_name=os.path.join(directory, sample + '_dendrogram'))

                split.visualize_history(np.log(1+X), x1, x2, genes, mhistory,
                                        save_name=os.path.join(directory, sample + '_mergeHistory'))

                split.save_more_highly_expressed_genes_in_one_clust(X, genes, map_label_to_nonzero(ym), x1, x2,
                                                                    num_genes=50, output_header=output_header,
                                                                    save_name=os.path.join(directory, sample_with_clust),
                                                                    show_plots=False, verbose=False)

                split.pairwise_cluster_comparison(X, genes, map_label_to_nonzero(ym), x1, x2, num_genes=50,
                                                  output_header=output_header,
                                                  save_name=os.path.join(directory, sample_with_clust),
                                                  show_plots=False, verbose=False)
                plt.close('all')

    shistory = split.filter_out_extraneous_steps(shistory, lowest_cutoff)

    if len(shistory) == 0:
        return

    directory = os.path.join(dir, 'splitHistory')
    if not os.path.exists(directory):
        os.makedirs(directory)

    split.visualize_history(np.log(1+X), x1, x2, genes, shistory, score_threshold=lowest_cutoff,
                            save_name=os.path.join(directory, sample))
    plt.close('all')

    split.save_history(genes, shistory, score_threshold=lowest_cutoff, num_genes=50, output_header=output_header,
                       save_name=os.path.join(directory, sample))

    return


def get_de_genes(dirname, len_header):
    files = os.path.join(dirname, '/*/*_cluster_features.csv')
    de_genes = []
    for f in glob.glob(files):
        with open(f) as fde:
            for i in range(len_header + 1):
                next(fde)
            genes = [line.strip().split(",")[1] for line in fde]
        de_genes.extend(genes)

    de_genes = list(set(de_genes))
    return de_genes


def combine_samples(table_list, extension, out_dir):

    names = []
    for table in table_list:
        # TODO: it is trivial to pass the list of libraries from CheckFastqs to here
        output_header, run_info = utils.grab_main_header(table)
        sample_name = run_info[2]
        if sample_name not in names:
            names.append(sample_name)
    name = '-'.join(names)

    table_rows = []

    if extension == 'csv':
        # check is same gene panel, i.e., all the genes in the panel match across the DTs that need to be combined
        # TODO: unpythonic loop
        for i in range(len(table_list)):
            with open(table_list[i], 'r') as f:
                reader = csv.reader(f)
                # extract the line that gives the column names, such as Cell_Index and gene names
                for line_idx in range(len(output_header) + 1):
                    header = next(reader)
                if i == 0:
                    column_names = header
                elif header != column_names:
                    print('Gene names in input files do not match!')
                    sys.exit(1)

        combined_DT = os.path.join(out_dir, name + '_DBEC_MolsPerCell.csv')
        with open(combined_DT, 'w') as g:
            rb = csv.writer(g)
            for row in output_header:
                rb.writerow(row)

            # output the row with column names
            rb.writerow(column_names)

            # add sample ID to cell label field and append to combined file, counts rows
            for table_idx, DT_mol in enumerate(table_list):
                rows = 0
                h = open(DT_mol, 'r')
                reader = csv.reader(h)
                # skip the output_header and the row with the column names
                for i in range(len(output_header) + 1):
                    next(reader)
                for read in reader:
                    read[0] += '--SampleID-' + str(table_idx + 1)
                    rb.writerow(read)
                    rows += 1
                h.close()
                table_rows.append(rows)

        X, genes = load_datatable(combined_DT, len(output_header))

    elif extension == 'st':
        for i in range(len(table_list)):
            print('Loading data from: {}' .format(os.path.basename(table_list[i])))
            data = np.genfromtxt(table_list[i], dtype=str, delimiter='\t', skip_header=len(output_header)+1)
            genes = np.unique(data[:, 1])

            # append-sample ID to cell-label column and count rows
            sample_id = '--SampleID-' + str(i + 1)
            labels = []
            for elem in data[:, 0]:
                elem += sample_id
                labels.append(elem)

            array_with_labels = np.column_stack((labels, data[:,1:]))
            cells = len(set(labels))
            table_rows.append(cells)

            if i == 0:
                gene_panel = genes.tolist()
                conc_array = array_with_labels

            else:
                # append to gene panel and array
                for gene in genes:
                    if gene not in gene_panel:
                        gene_panel.append(gene)
                conc_array = np.vstack((conc_array, array_with_labels))

        combined_DT = os.path.join(out_dir, name + '_Expression_Data.st')
        header = '\n'.join([item for sublist in output_header for item in sublist]) + '\n'
        header += '\t'.join(['Cell_Index--Sample_ID', 'Gene', 'Reads', 'Raw_Molecule', 'RSEC_Adjusted_Molecule',
                            'DBEC_Adjusted_Molecule']) + '\n'
        np.savetxt(combined_DT, conc_array, delimiter='\t', newline='\n', fmt="%s", header=header, comments='')

        X, genes = load_st(combined_DT, len(output_header))

    # record sample ID in output
    with open(os.path.join(out_dir, 'SampleIDs.csv'), 'w') as j:
        si = csv.writer(j)
        for row in output_header:
            si.writerow(row)
        header = ['Sample_ID', 'Sample_Name']
        si.writerow(header)
        for i in range(len(table_list)):
            for j in range(table_rows[i]):
                row = [str(i+1), str(os.path.basename(table_list[i].split('_')[0]))]
                si.writerow(row)

    return X, genes, name


if __name__ == '__main__':
    main()

