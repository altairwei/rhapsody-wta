---
title: "Sample Correlation Analysis"
output: html_document
---

```{r, setup, include=FALSE}
library(magrittr)
library(patchwork)
knitr::opts_chunk$set(echo = TRUE, autodep = TRUE)
```

## 样本相关行分析

首先准备两个主要的函数：

```{r}
sample_correlation_matrix <- function(
  data_folders,
  normalization = c("LogNormalize", "CLR", "RC", "SCTransform"),
  aggregation = c("avg", "sum"),
  correlation = c("pearson", "spearman", "kendall"),
  ...
) {
  normalization <- match.arg(normalization)
  aggregation <- match.arg(aggregation)
  correlation <- match.arg(correlation)

  fun_to_apply <- switch (aggregation,
    "sum" = Matrix::rowSums,
    "avg" = Matrix::rowMeans,
    Matrix::rowMeans
  )

  expr_df <- rhapsodykit::make_pseudo_bulk(
    data_folders,
    normalization = normalization,
    method = aggregation,
    ...
  )

  cormat <- cor(expr_df, method = correlation, use = "complete.obs")

  cormat
}

sample_correlation_heatmap <- function(
  cormat,
  matrix_name = NULL,
  simple_annotation = NULL,
  ...
) {
  p <- ComplexHeatmap::Heatmap(
    cormat,
    name = matrix_name,
    col = c("white", "red"),
    row_names_side = "left",
    row_dend_side = "left",
    column_names_side = "bottom",
    column_dend_side = "top",
    column_names_rot = 45,
    show_column_dend = FALSE,
    
    left_annotation = do.call(ComplexHeatmap::rowAnnotation, c(simple_annotation, show_annotation_name = FALSE)),
  
    cell_fun = function(j, i, x, y, width, height, fill) {
      grid::grid.text(
        sprintf("%.2f", cormat[i, j]),
        x, y, gp = grid::gpar(fontsize = 14)
      )
    },

    ...
  )

  p
}
```

然后准备样本数据：

```{r}
samples <- c(
  "0DPI-MOCK-1",
  "0DPI-MOCK-2",

  "1DPI-MOCK-1",
  "1DPI-MOCK-2",
  "1DPI-PNR2-1",
  "1DPI-PNR2-2",
  "1DPI-TR4-1",
  "1DPI-TR4-2",

  "2DPI-MOCK-1",
  "2DPI-MOCK-2",
  "2DPI-PNR2-1",
  "2DPI-PNR2-2",
  "2DPI-TR4-1",
  "2DPI-TR4-2",

  "3DPI-MOCK-1",
  "3DPI-MOCK-2",
  "3DPI-PNR2-1",
  #"3DPI-PNR2-2",
  "3DPI-PNR2-3",
  "3DPI-TR4-1",
  "3DPI-TR4-2"
)

data_folders <- paste0("../results/RawOutput/", samples)

perform_sample_correlation_analysis <- function(
  data_folders,
  normalization = c("LogNormalize", "CLR", "RC", "SCTransform"),
  aggregation = c("avg", "sum"),
  correlation = c("pearson", "spearman", "kendall"),
  group_rule = NULL,
  ...
) {
  cormat <- sample_correlation_matrix(
    data_folders,
    normalization = match.arg(normalization),
    aggregation = match.arg(aggregation),
    correlation = match.arg(correlation),
    ...
  )

  simple_annotation <- NULL

  if (!is.null(group_rule)) {
    groups <- structure(
      stringr::str_extract(
        basename(data_folders), group_rule),
      names = basename(data_folders)
    )
    groups <- groups[rownames(cormat)]

    simple_annotation <- list(group = groups)
  }

  matrix_name <- switch(
    match.arg(correlation),
    pearson = "Pearson's r",
    kendall = "Kendall's tau",
    spearman = "Spearman's rho"
  )

  sample_correlation_heatmap(
    cormat,
    matrix_name = matrix_name,
    simple_annotation = simple_annotation
  )
}
```

我们先用 pearson + LogNormalize 看一下：

```{r cache=TRUE, fig.height=12, fig.width=14, message=FALSE, warning=FALSE}
perform_sample_correlation_analysis(
  data_folders, "LogNormalize", "avg", "pearson", group_rule = "\\dDPI")
```

用 pearson + SCTransform:

```{r cache=TRUE, fig.height=12, fig.width=14, message=FALSE, warning=FALSE}
perform_sample_correlation_analysis(
  data_folders, "SCTransform", "avg", "pearson", group_rule = "\\dDPI", verbose = FALSE)
```


用 spearman + LogNormalize:

```{r cache=TRUE, fig.height=12, fig.width=14, warning=FALSE, message=FALSE}
perform_sample_correlation_analysis(
  data_folders, "LogNormalize", "avg", "spearman", group_rule = "\\dDPI")
```


我们用 spearman + SCTransform 看一下：

```{r cache=TRUE, fig.height=12, fig.width=14, warning=FALSE, message=FALSE}
perform_sample_correlation_analysis(
  data_folders, "SCTransform", "avg", "spearman", group_rule = "\\dDPI", verbose = FALSE)
```

## 样本数据集比较

### 样本整合后

#### 加载数据

```{r}
obj <- readRDS(Sys.glob(
  "../results/ObjectCache/IntegrationAndAnnotation/obj_annotated_*.rds"))
```

#### Get cell embeddings of PCA

```{r}
npc <- 10

expr_data <- Seurat::Embeddings(obj[["pca"]])[, 1:npc]

head(expr_data)
```

分割成不同样本的数据：

```{r}
mat_split <- function(x, f) {
  stopifnot(nrow(x) == length(f))
  lapply(split(x, f), matrix, ncol = ncol(x))
}

expr_list <- mat_split(expr_data, obj$sample)

str(expr_list)
```

矩阵的 “行” 应该是细胞，“列” 应该是 PCA 的不同轴。

这里我们需要去除完全重叠的点。

```{r}
expr_list <- lapply(expr_list, function(x) {
  x[!duplicated(x, MARGIN = 1),]
})
```


#### Calculate self-PDLR reference

```{r}
min_cells <- min(sapply(expr_list, nrow))

Xref <- xfun::cache_rds(
  file = "sc_xref.rds",
  dir = "../results/ObjectCache/IntegrationAndAnnotation/",
  hash = list(npc, min_cells),
  expr = DensityMorph::reference_distribution(npc, min_cells*100, min_cells)
)
```

It seems like `Xref` will determine the layout of final latent space.

#### Subsampling

```{r}
expr_list_down <- lapply(expr_list, function(x) {
  idx <- sample(1:nrow(x), min_cells, replace = FALSE)
  x[idx,]
})

str(expr_list_down)
```

#### Calculate latent space

```{r}
LS <- DensityMorph::latent_space(expr_list_down, Xref)
```

```{r}
sample_info <- stringr::str_match(names(expr_list_down), "^(.*)-(.*)-(.*)$")

data_to_plot <- LS$latent_space[, 1:2]
data_to_plot$Sample <- sample_info[, 1]
data_to_plot$Time <- sample_info[, 2]
data_to_plot$Treatment <- sample_info[, 3]

ggplot2::ggplot(data_to_plot, ggplot2::aes(
    x = A1, y = A2,
    fill = Treatment, color = Treatment, group = Treatment,
    shape = Time, label = Sample
  )) +
  ggplot2::geom_point(size = 3) +
  #ggrepel::geom_text_repel(color = "black") +
  ggplot2::scale_shape_manual(values = c(
    "0DPI" = 21, "1DPI" = 22, "2DPI" = 23, "3DPI" = 24
  )) +
  ggplot2::xlab("LSC1") +
  ggplot2::ylab("LSC2") +
  NULL
```


### 样本整合前

#### Load Seurat Object

```{r}
obj_list <- readRDS(Sys.glob(
  "../results/ObjectCache/IntegrationAndAnnotation/obj_list_transferred_*.rds"))

obj_merged <- merge(
  x = obj_list[[1]],
  y = obj_list[-1],
  add.cell.ids = names(obj_list)
)

obj_merged <- obj_merged %>%
  Seurat::NormalizeData(verbose = FALSE) %>%
  Seurat::FindVariableFeatures(selection.method = "vst", nfeatures = 2000) %>% 
  Seurat::ScaleData(verbose = FALSE) %>% 
  Seurat::RunPCA(features = NULL, npcs = 30, verbose = FALSE)
```

#### Get cell embeddings of PCA

```{r}
expr_data <- Seurat::Embeddings(obj_merged[["pca"]])[, 1:npc]

mat_split <- function(x, f) {
  stopifnot(nrow(x) == length(f))
  lapply(split(x, f), matrix, ncol = ncol(x))
}

expr_list <- mat_split(expr_data, obj_merged$sample)

str(expr_list)
```

Remove duplicated cells:

```{r}
expr_list <- lapply(expr_list, function(x) {
  x[!duplicated(x, MARGIN = 1),]
})
```

#### Calculate self-PDLR reference

`npc` and `min_cells` is same to integrated datasets, so we just use pre-calculated `Xref` above.

#### Subsampling

```{r}
expr_list_down <- lapply(expr_list, function(x) {
  idx <- sample(1:nrow(x), min_cells, replace = FALSE)
  x[idx,]
})

str(expr_list_down)
```

#### Calculate latent space

```{r}
LS <- DensityMorph::latent_space(expr_list_down, Xref)
```

```{r}
sample_info <- stringr::str_match(names(expr_list_down), "^(.*)-(.*)-(.*)$")

data_to_plot <- LS$latent_space[, 1:2]
data_to_plot$Sample <- sample_info[, 1]
data_to_plot$Time <- sample_info[, 2]
data_to_plot$Treatment <- sample_info[, 3]

ggplot2::ggplot(data_to_plot, ggplot2::aes(
    x = A1, y = A2,
    fill = Treatment, color = Treatment,
    shape = Time, label = Sample
  )) +
  ggplot2::geom_point(size = 3) +
  #ggrepel::geom_text_repel(color = "black") +
  ggplot2::scale_shape_manual(values = c(
    "0DPI" = 21, "1DPI" = 22, "2DPI" = 23, "3DPI" = 24
  )) +
  ggplot2::xlab("LSC1") +
  ggplot2::ylab("LSC2") +
  NULL
```


